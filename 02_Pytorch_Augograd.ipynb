{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916e1a4a",
   "metadata": {},
   "source": [
    "### AutoGrad in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9445cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd : Automatic Differentiation in Python, with a focus on machine learning.\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715e17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857c4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ee43d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x value is : 3.0\n",
      "y value is : 9.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"x value is : {x}\")\n",
    "print(f\"y value is : {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c1db51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #tensor(9., grad_fn=<PowBackward0>), where grad_fn shows that this tensor is the result of a computation that involved gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9245043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # compute the gradients, dy/dx and store them in x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73334c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # tensor(6.) which is the derivative of y with respect to x at x=3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7419c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dz_dx(x):\n",
    "    return 2*x*math.cos(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a6377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.466781571308061"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dx(3.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da08c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e40a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4da9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "972abbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960596fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90d2b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4121, grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b191fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc0277d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Inputs \n",
    "x = torch.tensor(6.7) # Input feature\n",
    "y = torch.tensor(0.0) # Target Output\n",
    "\n",
    "w = torch.tensor(1.0) # Weight\n",
    "b = torch.tensor(0.0) # Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbabd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss for scalar \n",
    "def binary_cross_entropy_loss(prediction, target):\n",
    "    epsilon = 1e-8  # To prevent log(0)\n",
    "    prediction = torch.clamp(prediction, epsilon, 1-epsilon)\n",
    "    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf6750cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: 0.998770534992218\n",
      "Loss Value: 6.701176166534424\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "z = w * x + b  \n",
    "y_pred = torch.sigmoid(z)\n",
    "loss = binary_cross_entropy_loss(y_pred, y)\n",
    "print(f\"Predicted Value: {y_pred.item()}\")\n",
    "print(f\"Loss Value: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04f1a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives\n",
    "# 1. dL/d(y_pred) : Loss with respect to predicted output\n",
    "dloss_by_pred = (y_pred - y) / (y_pred * (1-y_pred))\n",
    "\n",
    "# dy_pred/dz : Prediction (y_pred) with respect to z (sigmoid derivative)\n",
    "dy_pred_dz = y_pred * (1- y_pred)\n",
    "\n",
    "# dz/dw and dz/db : z with respect to w and b \n",
    "dz_dw = x # since z = w*x + b\n",
    "dz_db = 1\n",
    "\n",
    "dL_dw = dloss_by_pred * dy_pred_dz * dz_dw\n",
    "dL_db = dloss_by_pred * dy_pred_dz * dz_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "672441bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Gradient of loss w.r.t weight (dw) : 6.691762447357178\n",
      "Manual Gradient of loss w.r.t bias (db) : 0.998770534992218\n"
     ]
    }
   ],
   "source": [
    "print(f\"Manual Gradient of loss w.r.t weight (dw) : {dL_dw}\")\n",
    "print(f\"Manual Gradient of loss w.r.t bias (db) : {dL_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd0c81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will see the same using PyTorch Autograd where we don't have to compute gradients manually.\n",
    "# Setting requires_grad=True for w and b to track computations\n",
    "\n",
    "x = torch.tensor(6.7)\n",
    "y = torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7766ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce13e4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aac2190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3aeaf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = w * x + b\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "535f2750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.sigmoid(z)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef7a417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = binary_cross_entropy_loss(y_pred, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb15aa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m      2\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/autograd_example\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_graph(\u001b[38;5;28;01mlambda\u001b[39;00m w, b: torch\u001b[38;5;241m.\u001b[39msigmoid(w \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m b), (w, b))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_vendor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensorboard, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m Version(\n\u001b[1;32m      5\u001b[0m     tensorboard\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m      6\u001b[0m ) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/autograd_example')\n",
    "writer.add_graph(lambda w, b: torch.sigmoid(w * x + b), (w, b))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad05e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
